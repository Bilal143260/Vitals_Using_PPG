{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830e2f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24762fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Mon Mar 13 16:22:20 2023', '__version__': '1.0', '__globals__': [], 'd_noise_removed': array([[-0.11843242, -0.12225881, -0.1269756 , ..., -0.08550322,\n",
      "        -0.10230441, -0.06230696]])}\n"
     ]
    }
   ],
   "source": [
    "file_path = r'D:\\Internship\\PPG\\filteredandpeakdetectedsignals\\S1denoised'\n",
    "data = scipy.io.loadmat(file_path)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "909aefa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1509)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data['d_noise_removed']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8af747df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7312)\n"
     ]
    }
   ],
   "source": [
    "file_path_1 = r'D:\\Internship\\PPG\\filteredandpeakdetectedsignals\\S7denoised'\n",
    "data_1 = scipy.io.loadmat(file_path_1)['d_noise_removed']\n",
    "print(data_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de065a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7237)\n"
     ]
    }
   ],
   "source": [
    "file_path_2 = r'D:\\Internship\\PPG\\filteredandpeakdetectedsignals\\S6denoised'\n",
    "data_6 = scipy.io.loadmat(file_path_2)['d_noise_removed']\n",
    "print(data_6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce9404e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49fd4e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1509,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezed_data = np.squeeze(data)\n",
    "squeezed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58d0de25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11843242, -0.12225881, -0.1269756 , ..., -0.08550322,\n",
       "       -0.10230441, -0.06230696])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eba85b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_data = np.array_split(squeezed_data,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9697db3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(503,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "201680e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"test_array.npy\",splitted_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3327889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(503,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data = np.load(\"test_array.npy\")\n",
    "loaded_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8324536",
   "metadata": {},
   "source": [
    "## PRE-PROCESSING LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc6a9dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session</th>\n",
       "      <th>Index</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>O2 Saturation</th>\n",
       "      <th>Beats / min</th>\n",
       "      <th>Perfusion Index</th>\n",
       "      <th>Pleth Variability</th>\n",
       "      <th>Breaths / min</th>\n",
       "      <th>Time Stamp</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1678092555</td>\n",
       "      <td>3/6/2023</td>\n",
       "      <td>11:49:15</td>\n",
       "      <td>96</td>\n",
       "      <td>69</td>\n",
       "      <td>5.8</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>6/3/2023 8:49</td>\n",
       "      <td>3/6/2023 8:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1678092556</td>\n",
       "      <td>3/6/2023</td>\n",
       "      <td>11:49:16</td>\n",
       "      <td>96</td>\n",
       "      <td>68</td>\n",
       "      <td>6.0</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>6/3/2023 8:49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1678092557</td>\n",
       "      <td>3/6/2023</td>\n",
       "      <td>11:49:17</td>\n",
       "      <td>96</td>\n",
       "      <td>68</td>\n",
       "      <td>6.0</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>6/3/2023 8:49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1678092558</td>\n",
       "      <td>3/6/2023</td>\n",
       "      <td>11:49:18</td>\n",
       "      <td>97</td>\n",
       "      <td>68</td>\n",
       "      <td>6.1</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>6/3/2023 8:49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1678092559</td>\n",
       "      <td>3/6/2023</td>\n",
       "      <td>11:49:19</td>\n",
       "      <td>97</td>\n",
       "      <td>68</td>\n",
       "      <td>6.1</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>6/3/2023 8:49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Session  Index   Timestamp      Date      Time  O2 Saturation  Beats / min  \\\n",
       "0        1      1  1678092555  3/6/2023  11:49:15             96           69   \n",
       "1        1      2  1678092556  3/6/2023  11:49:16             96           68   \n",
       "2        1      3  1678092557  3/6/2023  11:49:17             96           68   \n",
       "3        1      4  1678092558  3/6/2023  11:49:18             97           68   \n",
       "4        1      5  1678092559  3/6/2023  11:49:19             97           68   \n",
       "\n",
       "   Perfusion Index Pleth Variability Breaths / min     Time Stamp  \\\n",
       "0              5.8                --            --  6/3/2023 8:49   \n",
       "1              6.0                --            --  6/3/2023 8:49   \n",
       "2              6.0                --            --  6/3/2023 8:49   \n",
       "3              6.1                --            --  6/3/2023 8:49   \n",
       "4              6.1                --            --  6/3/2023 8:49   \n",
       "\n",
       "     Unnamed: 11  \n",
       "0  3/6/2023 8:49  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\Internship\\PPG\\raw_label.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "648214bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    69\n",
       "1    68\n",
       "2    68\n",
       "3    68\n",
       "4    68\n",
       "Name: Beats / min, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Beats / min'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b699e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully with 570 records.\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the mean values\n",
    "means_list = []\n",
    "# Calculate the number of chunks\n",
    "num_chunks = len(df) // 10 + (1 if len(df) % 10 else 0)\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    # Calculate start and end indices for each chunk of 10 rows\n",
    "    start_idx = i * 10\n",
    "    end_idx = start_idx + 10\n",
    "    \n",
    "    # Calculate the mean of the current chunk for \"Beats / min\" column\n",
    "    chunk_mean = df['Beats / min'][start_idx:end_idx].mean()\n",
    "    \n",
    "    # Append the mean to the list, if the chunk is not empty\n",
    "    if not np.isnan(chunk_mean):\n",
    "        means_list.append(chunk_mean)\n",
    "\n",
    "# Create a new DataFrame for the mean values\n",
    "mean_df = pd.DataFrame(means_list, columns=['labels'])\n",
    "\n",
    "# Save the resulting DataFrame to a new CSV file\n",
    "mean_df.to_csv(r'D:\\Internship\\PPG\\labels.csv', index=False)\n",
    "\n",
    "print(f\"File saved successfully with {len(mean_df)} records.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c54738d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the \"Beats / min\" column is of a numeric type\n",
    "# df['Beats / min'] = pd.to_numeric(df['Beats / min'], errors='coerce')\n",
    "\n",
    "# Calculate the mean of every 10 values in the 'Beats / min' column\n",
    "means = df['Beats / min'].groupby(np.floor(np.arange(len(df)) / 10)).mean().reset_index(drop=True)\n",
    "\n",
    "# Create a new DataFrame for storing the mean values with the column name 'labels'\n",
    "mean_df = pd.DataFrame(means, columns=['labels'])\n",
    "\n",
    "# Save the resulting DataFrame to a new CSV file\n",
    "mean_df.to_csv(r'D:\\Internship\\PPG\\labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf58b0",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74584bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a766aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r'D:\\Internship\\PPG\\filteredandpeakdetectedsignals'\n",
    "output_dir = r'D:\\Internship\\PPG\\processed_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41b89817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S10denoised.mat', 'S11denoised.mat', 'S12denoised.mat', 'S13denoised.mat', 'S14denoised.mat', 'S15denoised.mat', 'S16denoised.mat', 'S17denoised.mat', 'S18denoised.mat', 'S19denoised.mat', 'S1denoised.mat', 'S20denoised.mat', 'S21denoised.mat', 'S2denoised.mat', 'S3denoised.mat', 'S4denoised.mat', 'S5denoised.mat', 'S6denoised.mat', 'S7denoised.mat', 'S8denoised.mat', 'S9denoised.mat', 'vPPG_sync.asv', 'vPPG_sync.m']\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(input_dir)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5f32a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    if file.endswith('.mat'):\n",
    "        file_path = os.path.join(input_dir,file)\n",
    "        data = scipy.io.loadmat(file_path)['d_noise_removed']\n",
    "        data = data.squeeze() #remove 1st dimension\n",
    "        \n",
    "        splits = int(len(data)/250)\n",
    "        sub_data = np.array_split(data,splits)\n",
    "        \n",
    "        for index,sub_array in enumerate(sub_data):\n",
    "            np.save(f\"{output_dir}\\{file}_{index}\",sub_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d1af4",
   "metadata": {},
   "source": [
    "## REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ceb039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory containing your .npy files\n",
    "npy_files_dir = r'D:\\Internship\\PPG\\Vitals_Using_PPG\\dataset\\features'\n",
    "\n",
    "# List all files in the directory and filter for .npy files\n",
    "npy_files = [file for file in os.listdir(npy_files_dir) if file.endswith('.npy')]\n",
    "\n",
    "# Sort the files if they are in a sequential order but named differently\n",
    "# npy_files.sort()\n",
    "\n",
    "# Load the .npy files\n",
    "features = []\n",
    "for file in npy_files:\n",
    "    filepath = os.path.join(npy_files_dir, file)\n",
    "    sample = np.load(filepath)\n",
    "    \n",
    "    # Truncate or keep the sample to the first 250 elements\n",
    "    if sample.shape[0] > 250:\n",
    "        truncated_sample = sample[:250]\n",
    "    else:\n",
    "        truncated_sample = sample\n",
    "    \n",
    "    features.append(truncated_sample)\n",
    "\n",
    "# Convert the list of numpy arrays into a single numpy array\n",
    "X = np.array(features)\n",
    "\n",
    "# Load labels\n",
    "labels_path = r'D:\\Internship\\PPG\\Vitals_Using_PPG\\dataset/labels.csv'\n",
    "y = pd.read_csv(labels_path)\n",
    "\n",
    "# Assuming your labels are in the first column\n",
    "y = y['labels'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daab8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "077d6987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ea6e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 10937389.66\n",
      "Coefficient of determination: -111422.31\n",
      "Mean Absolute Error: 483.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n",
    "# Calculate the MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294f48ae",
   "metadata": {},
   "source": [
    "# Unfiltered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3a521ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3d8fb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__header__': b'MATLAB 5.0 MAT-file, Platform: MACI64, Created on: Mon Mar 13 21:26:28 2023', '__version__': '1.0', '__globals__': [], 'pulseSigr': array([[67.55822386, 67.63502845, 67.58110147, ..., 63.14719377,\n",
      "        63.12000482, 63.16973717]])}\n"
     ]
    }
   ],
   "source": [
    "file_path = r'D:\\Internship\\PPG\\vppg kaust 2023 dataset rbg\\s1_r'\n",
    "data = scipy.io.loadmat(file_path)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5785449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1509)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data['pulseSigr']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862691d6",
   "metadata": {},
   "source": [
    "##### Number of samples in filtered and unfiltered data is same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7022eb3b",
   "metadata": {},
   "source": [
    "### Pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e75cfb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r'D:\\Internship\\PPG\\vppg kaust 2023 dataset rbg'\n",
    "output_dir = r'D:\\Internship\\PPG\\vppg raw G channel processed'\n",
    "\n",
    "files = [f for f in os.listdir(input_dir) if f.endswith('_g.mat')]\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith('.mat'):\n",
    "        file_path = os.path.join(input_dir,file)\n",
    "        data = scipy.io.loadmat(file_path)['pulseSigg']\n",
    "        data = data.squeeze() #remove 1st dimension\n",
    "        \n",
    "        splits = int(len(data)/250)\n",
    "        sub_data = np.array_split(data,splits)\n",
    "        \n",
    "        for index,sub_array in enumerate(sub_data):\n",
    "            np.save(f\"{output_dir}\\{file}_{index}\",sub_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22206a40",
   "metadata": {},
   "source": [
    "### Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0cabad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 368.50\n",
      "Coefficient of determination: -2.75\n",
      "Mean Absolute Error: 13.70\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory containing your .npy files\n",
    "npy_files_dir = r'D:\\Internship\\PPG\\vppg raw B channel processed'\n",
    "\n",
    "# List all files in the directory and filter for .npy files\n",
    "npy_files = [file for file in os.listdir(npy_files_dir) if file.endswith('.npy')]\n",
    "\n",
    "# Sort the files if they are in a sequential order but named differently\n",
    "# npy_files.sort()\n",
    "\n",
    "# Load the .npy files\n",
    "features = []\n",
    "for file in npy_files:\n",
    "    filepath = os.path.join(npy_files_dir, file)\n",
    "    sample = np.load(filepath)\n",
    "    \n",
    "    # Truncate or keep the sample to the first 250 elements\n",
    "    if sample.shape[0] > 250:\n",
    "        truncated_sample = sample[:250]\n",
    "    else:\n",
    "        truncated_sample = sample\n",
    "    \n",
    "    features.append(truncated_sample)\n",
    "\n",
    "# Convert the list of numpy arrays into a single numpy array\n",
    "X = np.array(features)\n",
    "\n",
    "# Load labels\n",
    "labels_path = r'D:\\Internship\\PPG\\Vitals_Using_PPG\\dataset/labels.csv'\n",
    "y = pd.read_csv(labels_path)\n",
    "\n",
    "# Assuming your labels are in the first column\n",
    "y = y['labels'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n",
    "# Calculate the MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b1b9d",
   "metadata": {},
   "source": [
    "# Filtering before Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b6cb41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca783a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 341.86\n",
      "Coefficient of determination: -2.48\n",
      "Mean Absolute Error: 12.64\n"
     ]
    }
   ],
   "source": [
    "# Function to apply a low-pass Butterworth filter\n",
    "def butter_lowpass(cutoff, nyquist, order=5):\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def lowpass_filter(data, cutoff, nyquist, order=5):\n",
    "    b, a = butter_lowpass(cutoff, nyquist, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "npy_files_dir = r'D:\\Internship\\PPG\\vppg raw b channel processed'\n",
    "npy_files = [file for file in os.listdir(npy_files_dir) if file.endswith('.npy')]\n",
    "\n",
    "features = []\n",
    "for file in npy_files:\n",
    "    filepath = os.path.join(npy_files_dir, file)\n",
    "    sample = np.load(filepath)\n",
    "    \n",
    "    if sample.shape[0] > 250:\n",
    "        truncated_sample = sample[:250]\n",
    "    else:\n",
    "        truncated_sample = sample\n",
    "    \n",
    "    cutoff_frequency =  0.5 # Cutoff frequency in Hz\n",
    "    nyquist_frequency = 15  # Nyquist frequency in Hz, which is half the sampling rate\n",
    "    filtered_sample = lowpass_filter(truncated_sample, cutoff_frequency, nyquist_frequency)\n",
    "    \n",
    "    features.append(filtered_sample)\n",
    "\n",
    "# Convert the list of numpy arrays into a single numpy array\n",
    "X = np.array(features)\n",
    "\n",
    "# Load labels\n",
    "labels_path = r'D:\\Internship\\PPG\\Vitals_Using_PPG\\dataset/labels.csv'\n",
    "y = pd.read_csv(labels_path)\n",
    "\n",
    "# Assuming your labels are in the first column\n",
    "y = y['labels'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n",
    "# Calculate the MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9e374e",
   "metadata": {},
   "source": [
    "# Other Regression Algos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0202c494",
   "metadata": {},
   "source": [
    "### LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "237f83fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f517db63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 38250\n",
      "[LightGBM] [Info] Number of data points in the train set: 456, number of used features: 250\n",
      "[LightGBM] [Info] Start training from score 72.781798\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Regressor\n",
      "Mean squared error: 73.98\n",
      "Coefficient of determination: 0.25\n",
      "Mean Absolute Error: 6.51\n"
     ]
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMRegressor(num_leaves=31, learning_rate=0.05, n_estimators=100)\n",
    "lgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric='l1')\n",
    "y_pred_lgb = lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration_)\n",
    "print('LightGBM Regressor')\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred_lgb))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred_lgb))\n",
    "print(f'Mean Absolute Error: {mean_absolute_error(y_test, y_pred_lgb):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c806f1c",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a7fc1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df1514da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regression\n",
      "Mean squared error: 98.49\n",
      "Coefficient of determination: -0.00\n",
      "Mean Absolute Error: 8.02\n"
     ]
    }
   ],
   "source": [
    "# Function to apply a low-pass Butterworth filter\n",
    "def butter_lowpass(cutoff, nyquist, order=5):\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def lowpass_filter(data, cutoff, nyquist, order=5):\n",
    "    b, a = butter_lowpass(cutoff, nyquist, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "npy_files_dir = r'D:\\Internship\\PPG\\vppg raw b channel processed'\n",
    "npy_files = [file for file in os.listdir(npy_files_dir) if file.endswith('.npy')]\n",
    "\n",
    "features = []\n",
    "for file in npy_files:\n",
    "    filepath = os.path.join(npy_files_dir, file)\n",
    "    sample = np.load(filepath)\n",
    "    \n",
    "    if sample.shape[0] > 250:\n",
    "        truncated_sample = sample[:250]\n",
    "    else:\n",
    "        truncated_sample = sample\n",
    "    \n",
    "    cutoff_frequency =  0.5 # Cutoff frequency in Hz\n",
    "    nyquist_frequency = 15  # Nyquist frequency in Hz, which is half the sampling rate\n",
    "    filtered_sample = lowpass_filter(truncated_sample, cutoff_frequency, nyquist_frequency)\n",
    "    \n",
    "    features.append(filtered_sample)\n",
    "\n",
    "# Convert the list of numpy arrays into a single numpy array\n",
    "X = np.array(features)\n",
    "\n",
    "# Load labels\n",
    "labels_path = r'D:\\Internship\\PPG\\Vitals_Using_PPG\\dataset/labels.csv'\n",
    "y = pd.read_csv(labels_path)\n",
    "\n",
    "# Assuming your labels are in the first column\n",
    "y = y['labels'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svr_model = SVR(C=1.0, epsilon=0.2)\n",
    "svr_model.fit(X_train, y_train)\n",
    "y_pred_svr = svr_model.predict(X_test)\n",
    "print('Support Vector Regression')\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred_svr))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred_svr))\n",
    "print(f'Mean Absolute Error: {mean_absolute_error(y_test, y_pred_svr):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b44fb",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2f4016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca1c8114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor\n",
      "Mean squared error: 74.93\n",
      "Coefficient of determination: 0.24\n",
      "Mean Absolute Error: 6.52\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print('Random Forest Regressor')\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred_rf))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred_rf))\n",
    "print(f'Mean Absolute Error: {mean_absolute_error(y_test, y_pred_rf):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95955d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
